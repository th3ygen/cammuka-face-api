<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Register & Recognize Face</title>
    
    <!-- Load face-api.js for local detection and Socket.IO for receiving data -->
    <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
    <script src="https://cdn.socket.io/4.7.5/socket.io.min.js"></script>

    <style>
        body {
            margin: 0;
            padding: 20px;
            box-sizing: border-box;
            width: 100vw;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            justify-content: flex-start;
            align-items: center;
            font-family: 'Inter', sans-serif;
            background-color: #121212;
            color: #e0e0e0;
            overflow-y: auto;
        }

        h1 {
            margin-bottom: 1rem;
            font-weight: 600;
            color: #ffffff;
        }

        .main-container {
            width: 100%;
            max-width: 1200px; /* Wider container for side-by-side view */
        }
        
        .ui-section {
            background-color: #1e1e1e;
            padding: 2rem;
            border-radius: 12px;
            box-shadow: 0 8px 25px rgba(0,0,0,0.3);
            margin-bottom: 2rem;
        }

        .ui-section h2 {
            text-align: center; margin-top: 0; font-weight: 500;
        }

        .input-group {
            display: flex; flex-direction: column; margin-bottom: 1.5rem;
        }

        .input-group label {
            margin-bottom: 0.5rem; font-size: 0.9rem; color: #bbbbbb;
        }
        
        input[type="file"] {
            width: 100%; padding: 0.75rem; border-radius: 8px; border: 1px solid #444;
            background-color: #2c2c2c; color: #ffffff; font-size: 1rem; box-sizing: border-box;
        }
        
        input[type="file"]::file-selector-button {
            background-color: #007bff; color: white; border: none; padding: 0.5rem 1rem;
            border-radius: 6px; cursor: pointer; transition: background-color 0.2s;
        }

        input[type="file"]::file-selector-button:hover { background-color: #0056b3; }

        .button {
            padding: 0.8rem 1.5rem; border: none; border-radius: 8px;
            background: linear-gradient(90deg, #007bff, #0056b3);
            color: white; font-size: 1.1rem; cursor: pointer;
            transition: transform 0.2s, box-shadow 0.2s;
            font-weight: 500; width: 100%; text-align: center;
        }
        
        .button:disabled { background: #555; cursor: not-allowed; }
        .button:not(:disabled):hover { transform: translateY(-2px); box-shadow: 0 4px 15px rgba(0, 123, 255, 0.4); }
        
        .divider {
            text-align: center; color: #888; margin: 2rem 0; position: relative;
        }
        .divider::before, .divider::after {
            content: ''; position: absolute; top: 50%; width: 40%; height: 1px; background: #444;
        }
        .divider::before { left: 0; }
        .divider::after { right: 0; }

        /* --- Live View Layout --- */
        #live-view-container {
            display: none; /* Hidden until recognition starts */
            flex-direction: row;
            gap: 2rem;
            align-items: flex-start;
        }

        #recognition-section { flex: 2; margin-bottom: 0; } /* Takes more space */
        #details-section { flex: 1; margin-bottom: 0; } /* Takes less space */

        .video-container {
            position: relative; width: 100%; padding-top: 77.78%;
            border-radius: 12px; overflow: hidden; background-color: #333;
        }

        video, canvas {
            position: absolute; top: 0; left: 0; width: 100%; height: 100%; object-fit: cover;
            transform: scaleX(-1);
        }

        /* --- Details Card Styling --- */
        #details-card-content { display: none; }
        #details-image {
            width: 100%; border-radius: 8px; margin-bottom: 1.5rem;
            border: 2px solid #444;
        }
        .details-text p {
            margin: 0.5rem 0; font-size: 1.1rem;
            padding: 0.5rem; border-radius: 6px; background-color: #2c2c2c;
            word-wrap: break-word; /* Ensure long values wrap */
        }
        .details-text p strong { color: #00aaff; }
        
        /* Loading Spinner */
        #loader {
            display: none;
            border: 5px solid #f3f3f3;
            border-radius: 50%;
            border-top: 5px solid #3498db;
            width: 50px;
            height: 50px;
            animation: spin 1s linear infinite;
            margin: 50px auto;
        }
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
        
        #save-section { display: none; }
        #status-message {
            position: fixed; top: 20px; left: 50%; transform: translateX(-50%);
            background-color: rgba(0,0,0,0.8); color: white; padding: 10px 20px;
            border-radius: 8px; z-index: 100; display: none; font-size: 1rem;
            backdrop-filter: blur(5px);
        }

        /* Responsive layout for smaller screens */
        @media (max-width: 900px) {
            #live-view-container {
                flex-direction: column;
            }
        }
    </style>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600&display=swap" rel="stylesheet">
</head>
<body>
    <div class="main-container">
        <h1>Face Recognition</h1>
        <div id="status-message">Loading AI Models...</div>

        <div id="registration-section" class="ui-section">
            <h2>Manage Face Data</h2>
            <div class="input-group">
                <label for="image-upload">Method A: Add or Update Faces from Images</label>
                <input type="file" id="image-upload" accept="image/png, image/jpeg" multiple>
            </div>
            <button id="register-button" class="button" disabled>Add/Update from Images</button>
            <div class="divider">OR</div>
            <div class="input-group">
                <label for="json-upload">Method B: Replace All with Saved Data</label>
                <input type="file" id="json-upload" accept="application/json">
            </div>
            <button id="load-json-button" class="button" disabled>Replace with File</button>
        </div>
        
        <div id="save-section" class="ui-section">
            <h2>Save Current Face Data</h2>
            <p>You can save all currently registered face data to a file for fast loading next time.</p>
            <button id="save-json-button" class="button">Save All Face Data</button>
        </div>

        <div id="live-view-container">
            <div id="recognition-section" class="ui-section">
                <h2>Live Recognition</h2>
                <div class="video-container">
                    <video id="video" autoplay muted playsinline></video>
                    <canvas id="canvas"></canvas>
                </div>
            </div>

            <div id="details-section" class="ui-section">
                <h2>Detected Person Details</h2>
                <div id="loader"></div>
                <div id="details-card-content">
                    <img id="details-image" src="" alt="Detected Person">
                    <div class="details-text" id="details-text-container">
                        <!-- Details will be populated here by JavaScript -->
                    </div>
                </div>
            </div>
        </div>
    </div>

    <script>
        // DOM Elements
        const registrationSection = document.getElementById('registration-section'),
            recognitionSection = document.getElementById('recognition-section'),
            saveSection = document.getElementById('save-section'),
            imageUpload = document.getElementById('image-upload'),
            jsonUpload = document.getElementById('json-upload'),
            registerButton = document.getElementById('register-button'),
            loadJsonButton = document.getElementById('load-json-button'),
            saveJsonButton = document.getElementById('save-json-button'),
            video = document.getElementById('video'),
            canvas = document.getElementById('canvas'),
            statusMessage = document.getElementById('status-message'),
            liveViewContainer = document.getElementById('live-view-container'),
            detailsSection = document.getElementById('details-section'),
            loader = document.getElementById('loader'),
            detailsCardContent = document.getElementById('details-card-content'),
            detailsImage = document.getElementById('details-image'),
            detailsTextContainer = document.getElementById('details-text-container'); // Container for all text details

        // State
        let labeledFaceDescriptors = [];
        let faceMatcher = null;
        let detectionInterval = null;
        let isVideoPlaying = false;
        const faceDetails = new Map();
        let currentlyDisplayedInmate = null;


        function showStatus(message, duration = 3000) {
            statusMessage.innerText = message;
            statusMessage.style.display = 'block';
            if (duration) setTimeout(() => statusMessage.style.display = 'none', duration);
        }
        
        // --- WebSocket Setup ---
        // 1. Plain WebSocket for SENDING data
        console.log('Attempting to connect to Data WebSocket at ws://recon.local:1337');
        const dataWebSocket = new WebSocket('ws://recon.local:1337');
        dataWebSocket.onopen = () => {
            console.log('Data WebSocket connection established.');
            showStatus('Data connection established.', 2000);
        };
        dataWebSocket.onerror = (error) => {
            console.error('Data WebSocket Error:', error);
            showStatus('Data WebSocket Error.', null);
        };
        dataWebSocket.onclose = () => {
            console.log('Data WebSocket connection closed.');
            showStatus('Data connection closed.', null);
        };

        // 2. Socket.IO for RECEIVING data
        console.log('Attempting to connect to Info Socket.IO at http://recon.local:5002');
        const infoSocket = io('http://recon.local:5002');
        infoSocket.on('connect', () => {
            console.log('Info Socket.IO connection established.');
            showStatus('Info connection established.', 2000)
        });
        infoSocket.on('disconnect', () => {
            console.log('Info Socket.IO connection lost.');
            showStatus('Info connection lost.', null)
        });
        
        infoSocket.on('match_found', (data) => {
            console.log('Received match_found event with data:', data);
            
            // Only update the card if it matches the inmate we are currently looking for
            if (currentlyDisplayedInmate === data.inmate_number) {
                
                // 1. Set the image: Prioritize the locally stored "uploaded" face image.
                const localDetails = faceDetails.get(data.inmate_number);
                if (localDetails && localDetails.imageUrl) {
                    detailsImage.src = localDetails.imageUrl;
                } else {
                    // Fallback to the server path or a placeholder if no local image is found
                    detailsImage.src = data.picpath || `https://placehold.co/400x400/2c2c2c/e0e0e0?text=${data.name.replace(' ', '+')}`;
                }
                detailsImage.onerror = () => {
                    detailsImage.src = `https://placehold.co/400x400/2c2c2c/e0e0e0?text=Image+Not+Found`;
                    detailsImage.onerror = null; // Prevent infinite loops
                };

                // 2. Display only the specified details
                detailsTextContainer.innerHTML = ''; // Clear previous details

                // Define the exact fields and their order
                const fieldsToShow = [
                    { key: 'name', label: 'Name' },
                    { key: 'category', label: 'Category' },
                    { key: 'inmate_number', label: 'Inmate Number' },
                    { key: 'admission_date', label: 'Admission Date' },
                    { key: 'release_date', label: 'Release Date' },
                    { key: 'case_number', label: 'Case Number' }
                ];
                
                fieldsToShow.forEach(field => {
                    // Check if the data from the server contains this key
                    if (data.hasOwnProperty(field.key)) {
                        const p = document.createElement('p');
                        p.innerHTML = `<strong>${field.label}:</strong> <span>${data[field.key]}</span>`;
                        detailsTextContainer.appendChild(p);
                    }
                });
                
                // 3. Show the updated card
                loader.style.display = 'none';
                detailsCardContent.style.display = 'block';
            } else {
                console.log(`Ignoring stale match data for ${data.inmate_number}. Currently displaying ${currentlyDisplayedInmate}.`);
            }
        });


        // --- START OF MODIFICATIONS ---

        // This new function will try to load face data from a file on the server.
        async function loadPredefinedFaceData() {
            try {
                // It expects 'face_data.json' to be in the same folder as this HTML file.
                const response = await fetch('face_data.json');
                if (!response.ok) {
                    throw new Error(`File not found or network error. Status: ${response.status}`);
                }
                const data = await response.json();
                
                // Load face descriptors from the file.
                labeledFaceDescriptors = data.descriptors.map(d => faceapi.LabeledFaceDescriptors.fromJSON(d));
                
                // Load associated details (like local image paths) if they exist.
                if (data.details) {
                   data.details.forEach(([key, value]) => faceDetails.set(key, value));
                }
                
                showStatus(`Auto-loaded ${labeledFaceDescriptors.length} people.`, 4000);
            } catch (error) {
                console.error('Could not auto-load face_data.json:', error);
                // If it fails, the user can still use the manual upload buttons.
                showStatus('Auto-load failed. Please use manual upload.', 5000);
            }
        }

        // Modified loadModels function to incorporate your desired startup sequence.
        async function loadModels() {
            const MODEL_URL = 'https://cdn.jsdelivr.net/gh/justadudewhohacks/face-api.js@0.22.2/weights';
            try {
                showStatus('Loading AI Models...', null);
                await Promise.all([
                    faceapi.nets.ssdMobilenetv1.loadFromUri(MODEL_URL),
                    faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),
                    faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL)
                ]);

                showStatus('Models Loaded! Loading face data...', null);
                await loadPredefinedFaceData(); // Attempt to load the predefined JSON file.
                
                // This function will start the camera and recognition if face data was loaded.
                startOrUpdateRecognition();

                // Enable the manual buttons as a fallback.
                registerButton.disabled = false;
                loadJsonButton.disabled = false;
            } catch (error) {
                console.error("Error during initial setup:", error);
                showStatus('Error loading models or face data. Please refresh.', null);
            }
        }
        
        // --- END OF MODIFICATIONS ---


        registerButton.addEventListener('click', async () => {
            const imageFiles = imageUpload.files;
            if (!imageFiles.length) {
                showStatus('Please select images to add.', 3000); return;
            }

            registerButton.disabled = true; loadJsonButton.disabled = true;
            showStatus(`Processing ${imageFiles.length} images...`, null);

            let facesLearned = 0;
            for (const file of imageFiles) {
                // Filename is the inmate number
                const inmateNumber = file.name.split('.').slice(0, -1).join('.');
                if (!inmateNumber) continue;
                showStatus(`Learning face for: ${inmateNumber}...`);

                try {
                    const image = await faceapi.bufferToImage(file);
                    const detection = await faceapi.detectSingleFace(image, new faceapi.SsdMobilenetv1Options()).withFaceLandmarks().withFaceDescriptor();
                    
                    if (detection) {
                        let existingLabel = labeledFaceDescriptors.find(d => d.label === inmateNumber);
                        if (existingLabel) {
                            existingLabel.descriptors.push(detection.descriptor);
                        } else {
                            labeledFaceDescriptors.push(new faceapi.LabeledFaceDescriptors(inmateNumber, [detection.descriptor]));
                        }
                        // Store image src (the "uploaded face") for local display
                        faceDetails.set(inmateNumber, { imageUrl: image.src });
                        facesLearned++;
                    }
                } catch (error) {
                    console.error(`Error processing image ${file.name}:`, error);
                }
            }
            
            showStatus(`Added/Updated ${facesLearned} faces.`, 4000);
            startOrUpdateRecognition();
            registerButton.disabled = false; loadJsonButton.disabled = false;
        });
        
        loadJsonButton.addEventListener('click', () => jsonUpload.click());
        jsonUpload.addEventListener('change', async (event) => {
            const file = event.target.files[0]; if (!file) return;
            showStatus('Loading and replacing face data...', null);
            const json = await file.text();
            const data = JSON.parse(json);
            
            labeledFaceDescriptors = data.descriptors.map(d => faceapi.LabeledFaceDescriptors.fromJSON(d));
            data.details.forEach(([key, value]) => faceDetails.set(key, value));
            showStatus(`Replaced data. Now recognizing ${labeledFaceDescriptors.length} people.`, 3000);
            startOrUpdateRecognition();
        });

        saveJsonButton.addEventListener('click', () => {
            if (labeledFaceDescriptors.length === 0) {
                showStatus('No face data to save!', 3000); return;
            }
            const dataToSave = {
                descriptors: labeledFaceDescriptors.map(ld => ld.toJSON()),
                details: Array.from(faceDetails.entries()) // Save the image URLs too
            };
            const jsonString = JSON.stringify(dataToSave, null, 2);
            const blob = new Blob([jsonString], { type: 'application/json' });
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = 'face_data.json';
            document.body.appendChild(a);
            a.click();
            document.body.removeChild(a);
            URL.revokeObjectURL(url);
            showStatus('Face data saved!', 3000);
        });

        async function startVideo() {
            if (isVideoPlaying) return;
            try {
                video.srcObject = await navigator.mediaDevices.getUserMedia({ video: {} });
                isVideoPlaying = true;
            } catch (err) {
                console.error("Error accessing webcam:", err);
                showStatus('Webcam access denied.', null);
            }
        }

        function startOrUpdateRecognition() {
            if (labeledFaceDescriptors.length === 0) {
                // Don't show an error on initial load if auto-load fails, just wait for manual upload.
                console.log("No faces registered yet. Waiting for user to upload data.");
                return;
            }
            
            liveViewContainer.style.display = 'flex';
            saveSection.style.display = 'block';
            faceMatcher = new faceapi.FaceMatcher(labeledFaceDescriptors, 0.55);
            showStatus(`Recognition started for ${labeledFaceDescriptors.length} people.`, 2000);
            startVideo();
        }

        // --- Live Detection & Data Request Flow ---
        video.addEventListener('play', () => {
            if (detectionInterval) clearInterval(detectionInterval);

            detectionInterval = setInterval(async () => {
                if (!faceMatcher || !isVideoPlaying) return;

                const displaySize = { width: video.clientWidth, height: video.clientHeight };
                faceapi.matchDimensions(canvas, displaySize);
                const detections = await faceapi.detectAllFaces(video, new faceapi.SsdMobilenetv1Options()).withFaceLandmarks().withFaceDescriptors();
                const resizedDetections = faceapi.resizeResults(detections, displaySize);
                const context = canvas.getContext('2d');
                context.clearRect(0, 0, canvas.width, canvas.height);

                let foundKnownPersonThisFrame = false;
                resizedDetections.forEach(detection => {
                    const bestMatch = faceMatcher.findBestMatch(detection.descriptor);
                    const box = detection.detection.box;
                    const text = bestMatch.toString();
                    const anchor = box.topLeft;
                    
                    // Draw the box using the library for simplicity
                    new faceapi.draw.DrawBox(box, {
                        label: '',
                        boxColor: 'rgba(0, 255, 0, 0.8)'
                    }).draw(canvas);

                    // Manually draw the text to counteract the video's horizontal flip
                    const font = '18px Inter';
                    context.font = font;
                    const textWidth = context.measureText(text).width;
                    const textHeight = 18;
                    const padding = 5;

                    // Calculate position for the label background
                    const labelX = anchor.x;
                    const labelY = anchor.y > (textHeight + (2 * padding)) ? anchor.y - (textHeight + (2 * padding)) : anchor.y + padding;
                    
                    context.save();
                    context.translate(labelX, labelY);
                    context.scale(-1, 1); // Flip context only for drawing text

                    // Draw background for the text
                    context.fillStyle = 'rgba(0, 255, 0, 0.8)';
                    context.fillRect(0, 0, -(textWidth + (2 * padding)), textHeight + (2 * padding));

                    // Draw the text
                    context.fillStyle = 'white';
                    context.fillText(text, -textWidth - padding, textHeight);
                    
                    context.restore(); // Restore context to its original state

                    if (bestMatch.label !== 'unknown') {
                        foundKnownPersonThisFrame = true;
                        // If we detect a new person (or the first person)
                        if (currentlyDisplayedInmate !== bestMatch.label) {
                            currentlyDisplayedInmate = bestMatch.label; // The label is the inmate number
                            console.log(`Detected inmate: ${currentlyDisplayedInmate}. Sending request...`);
                            
                            loader.style.display = 'block';
                            detailsCardContent.style.display = 'none';

                            // Send inmate number via plain WebSocket
                            if (dataWebSocket.readyState === WebSocket.OPEN) {
                                dataWebSocket.send(JSON.stringify({ number: currentlyDisplayedInmate }));
                                console.log(`Sent to ws://recon.local:1337:`, { number: currentlyDisplayedInmate });
                            } else {
                                console.error('Data WebSocket is not open. Cannot send request.');
                            }
                        }
                    }
                });

                if (!foundKnownPersonThisFrame && currentlyDisplayedInmate) {
                    currentlyDisplayedInmate = null;
                    loader.style.display = 'none';
                    detailsCardContent.style.display = 'none';
                }
            }, 1000);
        });

        // This starts the entire process when the page loads.
        loadModels();
    </script>
</body>
</html>
